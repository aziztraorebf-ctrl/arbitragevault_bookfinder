from typing import List, Optional, Dict, Any\nfrom decimal import Decimal\nfrom sqlalchemy import and_, or_, func, literal\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy.orm import Session\n\nfrom .base import BaseRepository, FilterCriteria, Page, DuplicateIsbnInBatchError\nfrom ..models.analysis import Analysis\n\nclass AnalysisRepository(BaseRepository[Analysis]):\n    \"\"\"Repository for Analysis operations with enhanced filtering and sorting\"\"\"\n    \n    # ✅ PATCH 2: Validation stricte des champs\n    SORTABLE_FIELDS = {\n        'roi_percent', 'velocity_score', 'profit', 'current_price', 'bsr', 'created_at'\n    }\n    \n    FILTERABLE_FIELDS = {\n        'roi_percent', 'velocity_score', 'profit', 'current_price', 'bsr', \n        'risk_level', 'isbn_or_asin'\n    }\n    \n    def __init__(self, session: Session):\n        super().__init__(session, Analysis)\n    \n    async def create_analysis(\n        self,\n        batch_id: int,\n        isbn_or_asin: str,\n        title: Optional[str] = None,\n        current_price: Optional[Decimal] = None,\n        target_price: Optional[Decimal] = None,\n        profit: Optional[Decimal] = None,\n        roi_percent: Optional[Decimal] = None,\n        velocity_score: Optional[Decimal] = None,\n        risk_level: Optional[str] = None,\n        bsr: Optional[int] = None,\n        raw_keepa: Optional[str] = None\n    ) -> Analysis:\n        \"\"\"Create new analysis with duplicate protection\"\"\"\n        \n        # Normaliser ISBN/ASIN\n        isbn_or_asin = isbn_or_asin.strip().upper()\n        \n        analysis = Analysis(\n            batch_id=batch_id,\n            isbn_or_asin=isbn_or_asin,\n            title=title,\n            current_price=current_price,\n            target_price=target_price,\n            profit=profit,\n            roi_percent=roi_percent,\n            velocity_score=velocity_score,\n            risk_level=risk_level,\n            bsr=bsr,\n            raw_keepa=raw_keepa\n        )\n        \n        try:\n            self.session.add(analysis)\n            await self.session.flush()  # Force constraint check\n            return analysis\n        except IntegrityError as e:\n            # ✅ PATCH 4: Gestion d'erreur avec rollback\n            await self.session.rollback()\n            if \"uq_batch_isbn\" in str(e.orig):\n                raise DuplicateIsbnInBatchError(\n                    f\"ISBN/ASIN {isbn_or_asin} already exists in batch {batch_id}\"\n                )\n            raise  # Re-raise other integrity errors\n    \n    async def list_filtered(\n        self,\n        batch_id: int,\n        filters: Optional[List[FilterCriteria]] = None,\n        isbn_list: Optional[List[str]] = None,  # ✅ PATCH 1: Support isbn_list\n        sort_by: Optional[str] = None,\n        sort_desc: bool = False,\n        page: int = 1,\n        page_size: int = 50,\n    ) -> Page[Analysis]:\n        \"\"\"List analyses with complex filtering including ISBN list\"\"\"\n        \n        query = self.session.query(Analysis).filter(Analysis.batch_id == batch_id)\n        \n        # ✅ PATCH 1: Filtrage par liste d'ISBN/ASIN\n        if isbn_list:\n            # Normaliser la liste\n            normalized_isbns = [isbn.strip().upper() for isbn in isbn_list]\n            query = query.filter(Analysis.isbn_or_asin.in_(normalized_isbns))\n        \n        # Application des autres filtres\n        if filters:\n            for criteria in filters:\n                if criteria.field not in self.FILTERABLE_FIELDS:\n                    raise InvalidFilterFieldError(f\"Field {criteria.field} is not filterable\")\n                \n                column = getattr(Analysis, criteria.field)\n                condition = self._build_filter_condition(column, criteria)\n                query = query.filter(condition)\n        \n        # ✅ PATCH 2: Validation stricte du tri via _paginate\n        return await self._paginate(query, page, page_size, sort_by, sort_desc)\n    \n    async def top_n_for_batch(\n        self,\n        batch_id: int,\n        strategy: str = \"balanced\",\n        limit: int = 10\n    ) -> List[Analysis]:\n        \"\"\"Get top N analyses for batch using specified strategy\"\"\"\n        \n        query = self.session.query(Analysis).filter(Analysis.batch_id == batch_id)\n        \n        if strategy == \"roi\":\n            query = query.order_by(Analysis.roi_percent.desc())\n        elif strategy == \"velocity\":\n            query = query.order_by(Analysis.velocity_score.desc())\n        elif strategy == \"profit\":\n            query = query.order_by(Analysis.profit.desc())\n        elif strategy == \"balanced\":\n            # ✅ PATCH 3: Stratégie balanced avec Decimal précis\n            balanced_score = (\n                Analysis.roi_percent * literal(Decimal(\"0.6\")) +\n                Analysis.velocity_score * literal(Decimal(\"0.4\"))\n            )\n            query = query.order_by(balanced_score.desc())\n        else:\n            raise ValueError(f\"Unknown strategy: {strategy}\")\n        \n        # Stable sort avec ID\n        query = query.order_by(Analysis.id.asc())\n        \n        return query.limit(limit).all()\n    \n    async def count_by_thresholds(\n        self,\n        batch_id: int,\n        roi_threshold: Optional[Decimal] = None,\n        velocity_threshold: Optional[Decimal] = None,\n        profit_threshold: Optional[Decimal] = None\n    ) -> Dict[str, int]:\n        \"\"\"Count analyses by various thresholds\"\"\"\n        \n        base_query = self.session.query(Analysis).filter(Analysis.batch_id == batch_id)\n        \n        results = {\n            \"total\": base_query.count()\n        }\n        \n        if roi_threshold:\n            results[\"high_roi\"] = base_query.filter(\n                Analysis.roi_percent >= roi_threshold\n            ).count()\n        \n        if velocity_threshold:\n            results[\"high_velocity\"] = base_query.filter(\n                Analysis.velocity_score >= velocity_threshold\n            ).count()\n        \n        if profit_threshold:\n            results[\"high_profit\"] = base_query.filter(\n                Analysis.profit >= profit_threshold\n            ).count()\n        \n        # Golden opportunities (multi-criteria)\n        if all([roi_threshold, velocity_threshold, profit_threshold]):\n            results[\"golden\"] = base_query.filter(\n                and_(\n                    Analysis.roi_percent >= roi_threshold,\n                    Analysis.velocity_score >= velocity_threshold,\n                    Analysis.profit >= profit_threshold\n                )\n            ).count()\n        \n        return results\n    \n    async def delete_by_batch(self, batch_id: int) -> int:\n        \"\"\"Delete all analyses for a batch\"\"\"\n        count = self.session.query(Analysis).filter(\n            Analysis.batch_id == batch_id\n        ).count()\n        \n        self.session.query(Analysis).filter(\n            Analysis.batch_id == batch_id\n        ).delete()\n        \n        return count\n    \n    async def delete_by_ids(self, analysis_ids: List[int]) -> int:\n        \"\"\"Delete analyses by ID list\"\"\"\n        count = self.session.query(Analysis).filter(\n            Analysis.id.in_(analysis_ids)\n        ).count()\n        \n        self.session.query(Analysis).filter(\n            Analysis.id.in_(analysis_ids)\n        ).delete(synchronize_session=False)\n        \n        return count\n"